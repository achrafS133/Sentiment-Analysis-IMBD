# ðŸŽ¬ IMDB Sentiment Analysis

Binary sentiment classification of IMDB movie reviews using NLP feature engineering and multiple ML models. This repository contains notebooks, dataset utilities, a model registry, and a compact summary of results.

---

## ðŸ“Œ Overview

- Clean and preprocess raw reviews (tokenization, normalization)
- Feature engineering with TFâ€‘IDF (1â€“2 nâ€‘grams, 5k features) and optional Word2Vec embeddings
- Train and compare several classifiers
- Persist trained artifacts and a model registry for reproducibility

---

## ðŸ§  Models Trained

- Logistic Regression (best performer)
- Multinomial Naive Bayes
- Random Forest
- Gradient Boosting
- Decision Tree

Cross-validation and GridSearchCV were applied to top models for stable performance.

---

## âš™ï¸ Setup

```powershell
# From the project root
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

If you prefer conda, create and activate an environment, then install from `requirements.txt`.

---

## ðŸ§ª Run the Notebook

You can explore end-to-end preprocessing, training, and evaluation directly in VS Code or Jupyter:

- Open `NLP_SENTIMENT_ANALYSIS.ipynb` and run cells sequentially
- Or open `NLP_Sentiment_Analysis_Complete.ipynb` for the full pipeline view

> Tip: In VS Code, use the â€œRun Allâ€ button in the notebook toolbar.

---

## ðŸ“Š Results (from notebook)

Summary below is derived from `sentiment_analysis_summary.txt` (full details inside the file):

- Dataset: 49,582 samples (Train: 39,665, Test: 9,917)
- Sentiment distribution: ~50/50 (negative: 24,698, positive: 24,884)
- Features: TFâ€‘IDF (5,000 features, 1â€“2 nâ€‘grams, min_df=2, max_df=0.8). Word2Vec 100â€‘dim available.

Top models by F1â€‘weighted on the test set:

- Logistic Regression: Accuracy 0.8872, F1 0.8871, ROCâ€‘AUC 0.9565
- Multinomial NB: Accuracy 0.8565, F1 0.8565, ROCâ€‘AUC 0.9314
- Random Forest: Accuracy 0.8441, F1 0.8441, ROCâ€‘AUC 0.9252

Additional artifacts produced in the notebook:

- Confusion matrices, ROC and PR curves (top models)
- Crossâ€‘validation score distributions

> Key insight: Logistic Regression is the best tradeâ€‘off of accuracy, AUC, and stability across folds.

---

## ðŸ“¦ Model Registry & Artifacts

- Trained models and metadata live under `models/`
- Registry files (JSON) provide details and paths, e.g. `model_registry_YYYYMMDD_HHMMSS.json`

Loading a saved model (example):

```python
import json, joblib, os

registry_path = os.path.join('models', 'model_registry_20251209_004604.json')
with open(registry_path, 'r', encoding='utf-8') as f:
	registry = json.load(f)

best_entry = max(registry['models'], key=lambda m: m.get('f1_weighted', 0))
model_path = best_entry['model_path']
vectorizer_path = registry.get('vectorizer_path')

clf = joblib.load(model_path)
vectorizer = joblib.load(vectorizer_path) if vectorizer_path else None

def predict_review(text: str):
	X = vectorizer.transform([text]) if vectorizer else [text]
	return clf.predict(X)[0]

print(predict_review("This movie was amazing! Great acting and story."))
```

---

## ðŸ§° Utilities

- `test_dataset.py`: quick dataset sanity check (shape, columns, sentiment distribution, sample review)

Run it:

```powershell
python .\test_dataset.py
```

---

## ðŸ“‚ Project Structure

```
Sentiment-Analysis-IMBD/
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ IMDBDataset.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model_registry_20251209_004604.json
â”‚   â”œâ”€â”€ registre_20251210_050945.json
â”‚   â””â”€â”€ registre_20251210_051134.json
â”œâ”€â”€ NLP_SENTIMENT_ANALYSIS.ipynb
â”œâ”€â”€ NLP_Sentiment_Analysis_Complete.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ sentiment_analysis_summary.txt
â”œâ”€â”€ test_dataset.py
â””â”€â”€ README.md
```

---

## ðŸš€ Next Steps

- Add a small CLI or FastAPI service for inference
- Track prediction confidence and set thresholds for business use
- Expand preprocessing (handling sarcasm, negations, domain adaptation)

---

## ðŸ­ MLOps Architecture

This project has been upgraded with a comprehensive MLOps pipeline:

### 1. ðŸš€ Production API & Explainability
High-performance FastAPI service for real-time inference.

- **Endpoints**:
  - `POST /predict`: Get sentiment (Positive/Negative) and confidence score.
  - `POST /explain`: Get feature contributions (why the model predicted X).
  - `GET /metrics`: Prometheus metrics for monitoring.
  - `GET /health`: Health check for k8s probes.

### 2. ðŸ³ Docker Ecosystem
Fully containerized stack for reproducible deployments.

```bash
# Start all services (API, MLflow, Prometheus, Grafana)
docker-compose -f docker/docker-compose.yml up --build -d
```

| Service | URL | Creds (Default) |
|---------|-----|-----------------|
| **API** | [http://localhost:8005](http://localhost:8005) | - |
| **Docs** | [http://localhost:8005/docs](http://localhost:8005/docs) | - |
| **MLflow** | [http://localhost:5005](http://localhost:5005) | - |
| **Grafana**| [http://localhost:3005](http://localhost:3005) | admin/admin |
| **Prometheus**| [http://localhost:9095](http://localhost:9095) | - |

### 3. ðŸ”„ Data Pipelines (DVC)
Reproducible data processing pipelines managed by DVC.

```bash
# Reproduce the entire pipeline (Ingestion -> Transform -> Train)
dvc repro
```

### 4. ðŸ“ˆ Continuous Integration
GitHub Actions workflow (`.github/workflows/ml-pipeline.yml`) ensures:
- Code quality (Black, Flake8, MyPy)
- Unit testing
- Automated model training on main branch push

---

## ðŸ™Œ Acknowledgments

Thanks to the open IMDB dataset and the Python ecosystem (scikitâ€‘learn, pandas, numpy, matplotlib).

